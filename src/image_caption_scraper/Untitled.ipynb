{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import itertools"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "phrase = \"I love to play football\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "words_pos = pos_tag(word_tokenize(phrase))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "words_pos"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('play', 'VB'),\n",
       " ('football', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "k = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "def generate_synonyms(phrase,k):\n",
    "\n",
    "    words_pos = pos_tag(word_tokenize(phrase))\n",
    "    \n",
    "    synonyms = []\n",
    "    for (word,pos) in words_pos:\n",
    "        temp = {}\n",
    "        wn_pos = get_wordnet_pos(pos)\n",
    "        if wn_pos:\n",
    "            for syn in wordnet.synsets(word,pos=wn_pos):\n",
    "                original = wordnet.synsets(word,pos=wn_pos)[0]\n",
    "                path_similarity = original.path_similarity(syn)\n",
    "                for l in syn.lemmas():\n",
    "                    if ((l.name() not in temp) or ((l.name() in temp) and (temp[l.name()]<path_similarity))):\n",
    "                        temp[l.name()] = original.path_similarity(syn)\n",
    "        else:\n",
    "            temp[word] = 1.0\n",
    "        \n",
    "        temp = list(dict(sorted(temp.items(), key=lambda item: item[1],reverse=True)).keys())[:k]\n",
    "        synonyms.append(temp)\n",
    "    \n",
    "    return synonyms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "phrase = \"I love to play football\"\n",
    "k = 10\n",
    "synonyms = generate_synonyms(phrase,k)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "results = []\n",
    "for element in itertools.product(*synonyms):\n",
    "    results.append(\" \".join(element))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "sentence = 'this is a foo bar sentences and i want to ngramize it'\n",
    "\n",
    "n = 6\n",
    "sixgrams = ngrams(sentence.split(), n)\n",
    "\n",
    "for grams in sixgrams:\n",
    "    print(grams)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('this', 'is', 'a', 'foo', 'bar', 'sentences')\n",
      "('is', 'a', 'foo', 'bar', 'sentences', 'and')\n",
      "('a', 'foo', 'bar', 'sentences', 'and', 'i')\n",
      "('foo', 'bar', 'sentences', 'and', 'i', 'want')\n",
      "('bar', 'sentences', 'and', 'i', 'want', 'to')\n",
      "('sentences', 'and', 'i', 'want', 'to', 'ngramize')\n",
      "('and', 'i', 'want', 'to', 'ngramize', 'it')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "from google_trans_new import google_translator\n",
    "from google_trans_new import LANGUAGES"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "!pip install translate"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.6.3-cp38-cp38-manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 6.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ali/anaconda3/envs/py38/lib/python3.8/site-packages (from translate) (2.25.1)\n",
      "Collecting libretranslatepy==2.1.1\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: click in /home/ali/.local/lib/python3.8/site-packages (from translate) (7.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ali/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->translate) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ali/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->translate) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ali/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->translate) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ali/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->translate) (2.10)\n",
      "Installing collected packages: lxml, libretranslatepy, translate\n",
      "Successfully installed libretranslatepy-2.1.1 lxml-4.6.3 translate-3.6.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ali/anaconda3/envs/py38/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "from translate import Translator\n",
    "translator= Translator(to_lang=\"\")\n",
    "translation = translator.translate(\"Good Morning!\")\n",
    "print(translation)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "import string\n",
    "chars = [c for c in string.ascii_uppercase]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "chars_double = [chars,chars]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "results = []\n",
    "for element in itertools.product(*chars_double):\n",
    "    results.append(\"\".join(element))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "from googletrans import Translator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "phrase = \" Ali Shibli\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "query = \"%\".join(phrase.split())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "query"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ali%Shibli'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "codes = \"\"\"\n",
    "aa\tAfar\thy\tArmenian\tor\tOriya\n",
    "ab\tAbkhaz\thz\tHerero\tos\tOssetian\n",
    "af\tAfrikaans\tid\tIndonesian\tpa\tPanjabi\n",
    "ak\tAkan\tig\tIgbo\tpl\tPolish\n",
    "am\tAmharic\tii\tNuosu\tps\tPashto\n",
    "an\tAragonese\tik\tInupiaq\tpt\tPortuguese\n",
    "ar\tArabic\tio\tIdo\tqu\tQuechua\n",
    "as\tAssamese\tis\tIcelandic\trm\tRomansh\n",
    "av\tAvaric\tit\tItalian\trn\tKirundi\n",
    "ay\tAymara\tiu\tInuktitut\tro\tRomanian\n",
    "az\tAzerbaijani\tja\tJapanese\tru\tRussian\n",
    "ba\tBashkir\tjv\tJavanese\trw\tKinyarwanda\n",
    "be\tBelarusian\tka\tGeorgian\tsa\tSanskrit\n",
    "bg\tBulgarian\tkg\tKongo\tsc\tSardinian\n",
    "bh\tBihari\tki\tKikuyu\tsd\tSindhi\n",
    "bi\tBislama\tkj\tKwanyama\tse\tNorthern Sami\n",
    "bm\tBambara\tkk\tKazakh\tsg\tSango\n",
    "bn\tBengali\tkl\tKalaallisut\tsi\tSinhala\n",
    "bo\tTibetan\tkm\tKhmer\tsk\tSlovak\n",
    "br\tBreton\tkn\tKannada\tsl\tSlovenian\n",
    "bs\tBosnian\tko\tKorean\tsm\tSamoan\n",
    "ca\tCatalan\tkr\tKanuri\tsn\tShona\n",
    "ce\tChechen\tks\tKashmiri\tso\tSomali\n",
    "ch\tChamorro\tku\tKurdish\tsq\tAlbanian\n",
    "co\tCorsican\tkv\tKomi\tsr\tSerbian\n",
    "cr\tCree\tkw\tCornish\tss\tSwati\n",
    "cs\tCzech\tky\tKyrgyz\tst\tSouthern Sotho\n",
    "cv\tChuvash\tlb\tLuxembourgish\tsu\tSundanese\n",
    "cy\tWelsh\tlg\tGanda\tsv\tSwedish\n",
    "da\tDanish\tli\tLimburgish\tsw\tSwahili\n",
    "de\tGerman\tln\tLingala\tta\tTamil\n",
    "dv\tDivehi\tlo\tLao\tte\tTelugu\n",
    "dz\tDzongkha\tlt\tLithuanian\ttg\tTajik\n",
    "ee\tEwe\tlu\tLuba-Katanga\tth\tThai\n",
    "el\tGreek\tlv\tLatvian\tti\tTigrinya\n",
    "en\tEnglish\tmg\tMalagasy\ttk\tTurkmen\n",
    "es\tSpanish\tmh\tMarshallese\ttl\tTagalog\n",
    "et\tEstonian\tmi\tMāori\ttn\tTswana\n",
    "eu\tBasque\tmk\tMacedonian\tto\tTonga\n",
    "fa\tPersian\tml\tMalayalam\ttr\tTurkish\n",
    "ff\tFula\tmn\tMongolian\tts\tTsonga\n",
    "fi\tFinnish\tmr\tMarathi\ttt\tTatar\n",
    "fj\tFijian\tms\tMalay\ttw\tTwi\n",
    "fo\tFaroese\tmt\tMaltese\tty\tTahitian\n",
    "fr\tFrench\tmy\tBurmese\tug\tUighur\n",
    "fy\tWestern Frisian\tna\tNauru\tuk\tUkrainian\n",
    "ga\tIrish\tnb\tNorwegian Bokmål\tur\tUrdu\n",
    "gd\tScottish Gaelic\tnd\tNorth Ndebele\tuz\tUzbek\n",
    "gl\tGalician\tne\tNepali\tve\tVenda\n",
    "gn\tGuaraní\tng\tNdonga\tvi\tVietnamese\n",
    "gu\tGujarati\tnl\tDutch\twa\tWalloon\n",
    "gv\tManx\tnn\tNorwegian Nynorsk\two\tWolof\n",
    "ha\tHausa\tno\tNorwegian\txh\tXhosa\n",
    "he\tHebrew\tnr\tSouth Ndebele\tyi\tYiddish\n",
    "hi\tHindi\tnv\tNavajo\tyo\tYoruba\n",
    "ho\tHiri Motu\tny\tChichewa\tza\tZhuang\n",
    "hr\tCroatian\toc\tOccitan\tzh\tChinese\n",
    "ht\tHaitian\toj\tOjibwe\tzu\tZulu\n",
    "hu\tHungarian\tom\tOromo\t\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "codes = codes.splitlines()\n",
    "codes = [code.split() for code in codes]\n",
    "codes = [code for code in codes if code]\n",
    "results = []\n",
    "for sublist in codes:\n",
    "    for code in sublist:\n",
    "        if len(code)==2: results.append(code)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'hy',\n",
       " 'or',\n",
       " 'ab',\n",
       " 'hz',\n",
       " 'os',\n",
       " 'af',\n",
       " 'id',\n",
       " 'pa',\n",
       " 'ak',\n",
       " 'ig',\n",
       " 'pl',\n",
       " 'am',\n",
       " 'ii',\n",
       " 'ps',\n",
       " 'an',\n",
       " 'ik',\n",
       " 'pt',\n",
       " 'ar',\n",
       " 'io',\n",
       " 'qu',\n",
       " 'as',\n",
       " 'is',\n",
       " 'rm',\n",
       " 'av',\n",
       " 'it',\n",
       " 'rn',\n",
       " 'ay',\n",
       " 'iu',\n",
       " 'ro',\n",
       " 'az',\n",
       " 'ja',\n",
       " 'ru',\n",
       " 'ba',\n",
       " 'jv',\n",
       " 'rw',\n",
       " 'be',\n",
       " 'ka',\n",
       " 'sa',\n",
       " 'bg',\n",
       " 'kg',\n",
       " 'sc',\n",
       " 'bh',\n",
       " 'ki',\n",
       " 'sd',\n",
       " 'bi',\n",
       " 'kj',\n",
       " 'se',\n",
       " 'bm',\n",
       " 'kk',\n",
       " 'sg',\n",
       " 'bn',\n",
       " 'kl',\n",
       " 'si',\n",
       " 'bo',\n",
       " 'km',\n",
       " 'sk',\n",
       " 'br',\n",
       " 'kn',\n",
       " 'sl',\n",
       " 'bs',\n",
       " 'ko',\n",
       " 'sm',\n",
       " 'ca',\n",
       " 'kr',\n",
       " 'sn',\n",
       " 'ce',\n",
       " 'ks',\n",
       " 'so',\n",
       " 'ch',\n",
       " 'ku',\n",
       " 'sq',\n",
       " 'co',\n",
       " 'kv',\n",
       " 'sr',\n",
       " 'cr',\n",
       " 'kw',\n",
       " 'ss',\n",
       " 'cs',\n",
       " 'ky',\n",
       " 'st',\n",
       " 'cv',\n",
       " 'lb',\n",
       " 'su',\n",
       " 'cy',\n",
       " 'lg',\n",
       " 'sv',\n",
       " 'da',\n",
       " 'li',\n",
       " 'sw',\n",
       " 'de',\n",
       " 'ln',\n",
       " 'ta',\n",
       " 'dv',\n",
       " 'lo',\n",
       " 'te',\n",
       " 'dz',\n",
       " 'lt',\n",
       " 'tg',\n",
       " 'ee',\n",
       " 'lu',\n",
       " 'th',\n",
       " 'el',\n",
       " 'lv',\n",
       " 'ti',\n",
       " 'en',\n",
       " 'mg',\n",
       " 'tk',\n",
       " 'es',\n",
       " 'mh',\n",
       " 'tl',\n",
       " 'et',\n",
       " 'mi',\n",
       " 'tn',\n",
       " 'eu',\n",
       " 'mk',\n",
       " 'to',\n",
       " 'fa',\n",
       " 'ml',\n",
       " 'tr',\n",
       " 'ff',\n",
       " 'mn',\n",
       " 'ts',\n",
       " 'fi',\n",
       " 'mr',\n",
       " 'tt',\n",
       " 'fj',\n",
       " 'ms',\n",
       " 'tw',\n",
       " 'fo',\n",
       " 'mt',\n",
       " 'ty',\n",
       " 'fr',\n",
       " 'my',\n",
       " 'ug',\n",
       " 'fy',\n",
       " 'na',\n",
       " 'uk',\n",
       " 'ga',\n",
       " 'nb',\n",
       " 'ur',\n",
       " 'gd',\n",
       " 'nd',\n",
       " 'uz',\n",
       " 'gl',\n",
       " 'ne',\n",
       " 've',\n",
       " 'gn',\n",
       " 'ng',\n",
       " 'vi',\n",
       " 'gu',\n",
       " 'nl',\n",
       " 'wa',\n",
       " 'gv',\n",
       " 'nn',\n",
       " 'wo',\n",
       " 'ha',\n",
       " 'no',\n",
       " 'xh',\n",
       " 'he',\n",
       " 'nr',\n",
       " 'yi',\n",
       " 'hi',\n",
       " 'nv',\n",
       " 'yo',\n",
       " 'ho',\n",
       " 'ny',\n",
       " 'za',\n",
       " 'hr',\n",
       " 'oc',\n",
       " 'zh',\n",
       " 'ht',\n",
       " 'oj',\n",
       " 'zu',\n",
       " 'hu',\n",
       " 'om']"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with open(\"codes.txt\",\"w\") as file:\n",
    "    for code in results:\n",
    "        file.write(code+\" \")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "open(\"codes.txt\").read().split()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'hy',\n",
       " 'or',\n",
       " 'ab',\n",
       " 'hz',\n",
       " 'os',\n",
       " 'af',\n",
       " 'id',\n",
       " 'pa',\n",
       " 'ak',\n",
       " 'ig',\n",
       " 'pl',\n",
       " 'am',\n",
       " 'ii',\n",
       " 'ps',\n",
       " 'an',\n",
       " 'ik',\n",
       " 'pt',\n",
       " 'ar',\n",
       " 'io',\n",
       " 'qu',\n",
       " 'as',\n",
       " 'is',\n",
       " 'rm',\n",
       " 'av',\n",
       " 'it',\n",
       " 'rn',\n",
       " 'ay',\n",
       " 'iu',\n",
       " 'ro',\n",
       " 'az',\n",
       " 'ja',\n",
       " 'ru',\n",
       " 'ba',\n",
       " 'jv',\n",
       " 'rw',\n",
       " 'be',\n",
       " 'ka',\n",
       " 'sa',\n",
       " 'bg',\n",
       " 'kg',\n",
       " 'sc',\n",
       " 'bh',\n",
       " 'ki',\n",
       " 'sd',\n",
       " 'bi',\n",
       " 'kj',\n",
       " 'se',\n",
       " 'bm',\n",
       " 'kk',\n",
       " 'sg',\n",
       " 'bn',\n",
       " 'kl',\n",
       " 'si',\n",
       " 'bo',\n",
       " 'km',\n",
       " 'sk',\n",
       " 'br',\n",
       " 'kn',\n",
       " 'sl',\n",
       " 'bs',\n",
       " 'ko',\n",
       " 'sm',\n",
       " 'ca',\n",
       " 'kr',\n",
       " 'sn',\n",
       " 'ce',\n",
       " 'ks',\n",
       " 'so',\n",
       " 'ch',\n",
       " 'ku',\n",
       " 'sq',\n",
       " 'co',\n",
       " 'kv',\n",
       " 'sr',\n",
       " 'cr',\n",
       " 'kw',\n",
       " 'ss',\n",
       " 'cs',\n",
       " 'ky',\n",
       " 'st',\n",
       " 'cv',\n",
       " 'lb',\n",
       " 'su',\n",
       " 'cy',\n",
       " 'lg',\n",
       " 'sv',\n",
       " 'da',\n",
       " 'li',\n",
       " 'sw',\n",
       " 'de',\n",
       " 'ln',\n",
       " 'ta',\n",
       " 'dv',\n",
       " 'lo',\n",
       " 'te',\n",
       " 'dz',\n",
       " 'lt',\n",
       " 'tg',\n",
       " 'ee',\n",
       " 'lu',\n",
       " 'th',\n",
       " 'el',\n",
       " 'lv',\n",
       " 'ti',\n",
       " 'en',\n",
       " 'mg',\n",
       " 'tk',\n",
       " 'es',\n",
       " 'mh',\n",
       " 'tl',\n",
       " 'et',\n",
       " 'mi',\n",
       " 'tn',\n",
       " 'eu',\n",
       " 'mk',\n",
       " 'to',\n",
       " 'fa',\n",
       " 'ml',\n",
       " 'tr',\n",
       " 'ff',\n",
       " 'mn',\n",
       " 'ts',\n",
       " 'fi',\n",
       " 'mr',\n",
       " 'tt',\n",
       " 'fj',\n",
       " 'ms',\n",
       " 'tw',\n",
       " 'fo',\n",
       " 'mt',\n",
       " 'ty',\n",
       " 'fr',\n",
       " 'my',\n",
       " 'ug',\n",
       " 'fy',\n",
       " 'na',\n",
       " 'uk',\n",
       " 'ga',\n",
       " 'nb',\n",
       " 'ur',\n",
       " 'gd',\n",
       " 'nd',\n",
       " 'uz',\n",
       " 'gl',\n",
       " 'ne',\n",
       " 've',\n",
       " 'gn',\n",
       " 'ng',\n",
       " 'vi',\n",
       " 'gu',\n",
       " 'nl',\n",
       " 'wa',\n",
       " 'gv',\n",
       " 'nn',\n",
       " 'wo',\n",
       " 'ha',\n",
       " 'no',\n",
       " 'xh',\n",
       " 'he',\n",
       " 'nr',\n",
       " 'yi',\n",
       " 'hi',\n",
       " 'nv',\n",
       " 'yo',\n",
       " 'ho',\n",
       " 'ny',\n",
       " 'za',\n",
       " 'hr',\n",
       " 'oc',\n",
       " 'zh',\n",
       " 'ht',\n",
       " 'oj',\n",
       " 'zu',\n",
       " 'hu',\n",
       " 'om']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import uuid\n",
    "print(uuid.uuid4())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14d46e56-ec27-4642-97e7-4faba3451c69\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "data = json.load(open(\"images/google/رجاءا_تعال_الي/رجاءا_تعال_الي.json\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "data.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['ac40c7dc-9169-4af2-b2be-f786fe94712c.jpg', 'b4fb3d17-b52c-437e-8f34-e68835604554.jpg', 'b56719c9-b7b4-469c-b6c0-8e10ad657d51.jpg', '25ed062c-5480-4a81-8037-a51ca907e3bb.jpg', '3e5b1d71-370b-43eb-b1c7-604751c4ee20.jpg', '10743a42-5fa9-4bc0-a25d-d36287465014.jpg', '911e118e-9bfa-4383-bef8-fc128f128609.jpg', 'e22e2740-1881-4c6c-b369-a49f90566dc6.jpg', 'bbc3abe5-e59f-4eb2-8ebc-d785220ef0f4.jpg', '7cc326ab-f354-4b40-9089-756e1ae29830.jpg', 'b3292390-03ce-47dc-8119-6a569c6086fa.jpg', 'ad72b89e-fa28-46cc-b466-a0719d56fd6d.jpg', 'e0425119-7169-4ff1-a8f8-6d9342796f57.jpg', '7fce8823-e088-4c8b-9a3c-0ec82fa7dded.jpg', '30d5b3fc-2a8e-4e2c-ba98-a18921089290.jpg', 'cd998322-40cc-4fdf-9832-6b942a92e30d.jpg', '04e4929a-5a4c-4a1a-b70e-95dcd0feb374.jpg', '2258afd8-64d1-4ff0-9837-3875c794325d.jpg', '2145d4c8-6b4e-4133-a16c-48fedf8de9e0.jpg', 'ba0f0d88-4a44-4ef0-852c-e02bb3ac113a.jpg', '0ef4c8be-211b-4435-8dda-c82a6ea6ea6b.jpg', '46d5c8b0-ffa4-4555-a5dd-aa1db241393a.jpg', '6faf0192-4dad-45b7-8d1a-182556dbfaea.jpg', 'b8c6822f-854c-40e5-a498-6750002d263e.jpg', '7fe263e1-f640-4f99-8239-b364d4c1fe30.jpg', '45f24b9b-8d97-4b5f-b95d-54aa153911cf.jpg', '10348902-c648-43c0-9b32-dbe3b2cd2bcb.jpg', '8874ea20-e97d-4efb-acb1-2822abbf4442.jpg', '27817a29-341d-43ae-88c7-9e501b2100db.jpg', 'bf8ac1e2-4830-43ce-bfdc-43f64c09f710.jpg', 'f87d0e08-3657-4666-a01f-b929cd412897.jpg', '2c15e948-29f0-4570-a4c6-65e1d4fd8ded.jpg', '9e445c7d-0930-461d-a0ba-6f066fb4711e.jpg', 'c13ba000-24d9-4cfc-961f-e714923d2648.jpg', '6bdbc001-772c-4a44-88e3-980c03388b0c.jpg', '016352f1-0882-4873-8512-726e46567ee2.jpg', 'abb59b3c-6b9c-4657-bfee-f334d17fa39d.jpg', 'a8517532-6686-4bbb-acdd-f1fd74750a53.jpg', '02b5e5f3-d3e6-48a1-bd30-cc521a4262ca.jpg', '331327a9-8444-4815-916a-523c8ec6d66e.jpg', 'fe1cf5ef-85d3-4f40-ab1f-7da1d8c6e9bb.jpg', 'c25b13ea-f6bb-49b7-8538-2def006f4743.jpg', 'ef31fb60-1430-4f8b-b902-20e3c46f4355.jpg', '93c761a5-83d0-4adc-be71-d081a93aa60d.jpg', 'cd1161b1-92fb-43d1-b05d-d5940d525518.jpg', '340bdf99-257c-4982-84df-25f30c9091ab.jpg', '0109983b-b45d-465c-a747-8d8fb8e600a3.jpg', 'c253eb8b-da4f-4679-b5a9-3ebc7d64ad5b.jpg', '1dbcfd81-c589-4117-bc97-71d467ae1d3a.jpg', '11710962-e7fe-4e4d-a50c-85405f107583.jpg', 'bc366e60-774b-44a3-ae65-5d529c56b4a2.jpg', 'f76710d8-9cd8-4973-8c88-a11b896baeb3.jpg', '514229cf-34e6-4532-ae2f-0325fae6f1ae.jpg', '9c1c06f2-47ed-4d62-9c96-f7891de05494.jpg', '8ed71fc9-785e-470f-9843-96049692772f.jpg', '47fd07d6-f0dd-4d60-b996-a56cdd728183.jpg', '2879dc31-85f1-4b7d-9207-26095c20c16b.jpg', 'f12d9b3a-0e32-4c31-80a5-afafe7f6a476.jpg'])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "cfg = {\n",
    "    \"engine\": \"all\",\n",
    "    \"num_images\": 100,\n",
    "    \"query\": \"dog chases cat\",\n",
    "    \"out_dir\": \"images\",\n",
    "    \"headless\": True,\n",
    "    \"driver\": \"chromedriver\",\n",
    "    \"expand\": True,\n",
    "    \"k\": 3,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(cfg, fp, indent=4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "args=json.load(open(\"data.json\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38': conda)"
  },
  "interpreter": {
   "hash": "c7a102144ce893933cd37896a1f005cbbe32ffdbc8d8326d8c66c447a89a238a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}